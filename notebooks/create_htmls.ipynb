{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classes\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from jinja2.exceptions import UndefinedError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining paths\n",
    "GROUP_DATA_DIR = Path(\"group-data\")\n",
    "\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-group.github.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create proper HTML file names by replacing spaces with underscores\n",
    "def page_link(a):\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the Environment class that looks for templates. Page_link is set to the global variable so that it can be accessed by all templates\n",
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary to store content data\n",
    "content_id_data = {\"article_id\": [], \"category\": [], \"date\": [], \"tags\": []}\n",
    "\n",
    "# Looping through JSON files in the content directory and extracting relevant data\n",
    "for json_file in os.listdir(CONTENT_DIR_PATH):\n",
    "    if json_file.endswith(\".json\"):\n",
    "        json_path = os.path.join(CONTENT_DIR_PATH, json_file)\n",
    "        with open(json_path, \"r\") as file:\n",
    "            info = json.load(file)\n",
    "            if info.get(\"display\"):\n",
    "                content_id_data[\"article_id\"].append(info.get(\"article_id\"))\n",
    "                content_id_data[\"category\"].append(info.get(\"category\"))\n",
    "                content_id_data[\"date\"].append(info.get(\"article_date\"))\n",
    "                content_id_data[\"tags\"].append(info.get(\"tags\"))\n",
    "\n",
    "# Creating a DataFrame from the extracted content data and sorting it\n",
    "content_df = pd.DataFrame(content_id_data)\n",
    "content_df[\"date\"] = pd.to_datetime(content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "content_df = (\n",
    "    content_df.groupby(\"category\")\n",
    "    .apply(lambda x: x.sort_values(\"date\", ascending=False))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/bxm54w1d3tn2gj52lyx4vp200000gn/T/ipykernel_20444/1929342121.py:7: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  research_content_unsorted.groupby(\"category\")\n"
     ]
    }
   ],
   "source": [
    "# Separating content into research and news categories and sorting them\n",
    "\n",
    "research_content_unsorted = content_df[\n",
    "    content_df[\"tags\"].apply(lambda x: any(\"research\" in tag for tag in x))\n",
    "]\n",
    "research_content = (\n",
    "    research_content_unsorted.groupby(\"category\")\n",
    "    .apply(lambda x: x.sort_values(\"date\", ascending=False))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_content_unsorted = content_df[\n",
    "    content_df[\"tags\"].apply(lambda x: any(\"news\" in tag for tag in x))\n",
    "]\n",
    "news_content = news_content_unsorted.sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for the latest content\n",
    "latest_content_df = pd.DataFrame()\n",
    "\n",
    "# Iterating through content categories to find the latest content or topmost dict for each category\n",
    "for category in content_df.category.unique():\n",
    "    latest_data = pd.Series(content_df[content_df.category == category].iloc[0])\n",
    "    latest_content_df = latest_content_df._append(latest_data, ignore_index=True)\n",
    "\n",
    "latest_content_df[\"date\"] = pd.to_datetime(latest_content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "latest_content_df = latest_content_df.sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\"general\", \"homepage\", \"research\", \"support\", \"contact\"] # List of JSON files to be processed\n",
    "\n",
    "data = {}\n",
    "# Looping through JSON files and loading their content into the 'data' dictionary\n",
    "for json_file in json_files:\n",
    "    json_file_path = WEBSITE_DATA_PATH / f\"{json_file}.json\"\n",
    "\n",
    "    try:\n",
    "        with open(json_file_path, \"r\") as json_var:\n",
    "            data[json_file] = json.load(json_var)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering the homepage template with data and saving it to a file\n",
    "homepage_template = environment.get_template(\"homepage.html.j2\")\n",
    "# Passing lists to jinja2 template\n",
    "homepage_content = homepage_template.render(\n",
    "    general=data[\"general\"],\n",
    "    homepage=data[\"homepage\"],\n",
    "    recent_content=latest_content_df.to_dict(orient=\"records\"),\n",
    ")\n",
    "homepage_file_path = HOSTING_PATH / \"Index.html\"\n",
    "\n",
    "with open(homepage_file_path, mode=\"w\", encoding=\"utf-8\") as homepage:\n",
    "    homepage.write(homepage_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### People Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse member data from JSON files\n",
    "\n",
    "def parse_member_data(member_dir):\n",
    "    member_json_dir = member_dir / \"jsons\"\n",
    "    education_experience_list = []\n",
    "    file_names = [\"experiences.json\", \"education.json\"]\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_path = member_json_dir / file_name\n",
    "        if file_path.exists():\n",
    "            with open(file_path, \"r\") as f:\n",
    "                education_experience_list += json.load(f)\n",
    "        else:\n",
    "            print(file_path)\n",
    "\n",
    "    # Load social links directly\n",
    "    social_links = {}\n",
    "    social_links_file_path = member_json_dir / \"social_links.json\"\n",
    "    if social_links_file_path.exists():\n",
    "        with open(social_links_file_path, \"r\") as f:\n",
    "            social_links = json.load(f)\n",
    "\n",
    "    # Load topmost project title\n",
    "    current_project_title = None\n",
    "    projects_file_path = member_json_dir / \"projects.json\"\n",
    "    if projects_file_path.exists():\n",
    "        with open(projects_file_path, \"r\") as f:\n",
    "            projects = json.load(f)\n",
    "            if projects:  # ensure it's not an empty list\n",
    "                current_project_title = projects[0].get(\"project_title\")\n",
    "\n",
    "    return pd.DataFrame(education_experience_list), social_links, current_project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>institution</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>role</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>degree</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michigan State University</td>\n",
       "      <td>East Lansing</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York University</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>Senior Research Associate</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>European Southern Observatory</td>\n",
       "      <td>Garching</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>DE</td>\n",
       "      <td>ESO Fellow</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>Postdoctoral Fellow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australian National University</td>\n",
       "      <td>Canberra</td>\n",
       "      <td></td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>2011-12-18</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Physics and Astronomy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      institution          city     state    country  \\\n",
       "0       Michigan State University  East Lansing  Michigan         US   \n",
       "1             New York University      New York  New York         US   \n",
       "2   European Southern Observatory      Garching   Bavaria         DE   \n",
       "3           University of Toronto       Toronto   Ontario     Canada   \n",
       "4  Australian National University      Canberra            Australia   \n",
       "\n",
       "                        role  start_date    end_date               degree  \\\n",
       "0        Assistant Professor  2019-08-15         NaN                  NaN   \n",
       "1  Senior Research Associate  2019-01-01  2019-12-31                  NaN   \n",
       "2                 ESO Fellow  2014-10-01  2018-12-31                  NaN   \n",
       "3                        NaN  2011-10-01  2014-09-30  Postdoctoral Fellow   \n",
       "4                        NaN  2007-02-01  2011-12-18                  PhD   \n",
       "\n",
       "                 subject  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4  Physics and Astronomy  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " member_dir = Path(\"/Users/harshul/projects/kgwebsite/group-data/members/wolfgang_kerzendorf\")\n",
    " parse_member_data(member_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract academic roles from education and experience data\n",
    "\n",
    "def extract_member_academic_role(education_experience_df):\n",
    "    # Check if these columns exist in dataframe\n",
    "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
    "        if column not in education_experience_df.columns:\n",
    "            education_experience_df[column] = None\n",
    "\n",
    "    current_academic_role = None\n",
    "\n",
    "    role_map = {\n",
    "        \"Assistant Professor\": \"Professor\",\n",
    "        \"Professor\": \"Professor\",\n",
    "        \"Visualization Consultant\": \"Visualization Consultant\",\n",
    "        \"Research Consultant\": \"Research Consultant\",\n",
    "        \"Research Software Engineer\": \"Research Software Engineer\",\n",
    "        \"Professorial Assistant\": \"Undergraduate\",\n",
    "        \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
    "        \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
    "    }\n",
    "\n",
    "    degree_map = {\n",
    "        \"Masters\": \"Graduate Student\",\n",
    "        \"PhD\": \"Postdoctorate\", #  if end_date is present\n",
    "        \"Bachelors\": \"Graduate Student\",\n",
    "    }\n",
    "\n",
    "    for _, row in education_experience_df.iterrows():\n",
    "        role = row.get(\"role\", None)\n",
    "        degree = row.get(\"degree\", None)\n",
    "\n",
    "        if not current_academic_role:\n",
    "            current_academic_role = role_map.get(role, \"\")\n",
    "\n",
    "            if degree == \"PhD\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Graduate Student\" # if end_date is NaN\n",
    "            elif degree == \"Bachelors\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Undergraduate Student\"\n",
    "            elif not current_academic_role and degree in degree_map:\n",
    "                current_academic_role = degree_map[degree]\n",
    "\n",
    "    # Check for end dates outside the loop\n",
    "    has_end_date = all(\n",
    "        not pd.isna(date) for date in education_experience_df[\"end_date\"]\n",
    "    )\n",
    "    is_current_member = not has_end_date\n",
    "\n",
    "    return current_academic_role, is_current_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harshul/projects/kgwebsite/group-data/members/josh_shields\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/anirban_dutta\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/erin_visser\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/erin_visser/jsons/experiences.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/.DS_Store\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/vicente_amado\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/vicente_amado/jsons/experiences.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/yuki_matsumura\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/yuki_matsumura/jsons/experiences.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/andrew_fullard\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/isaac_smith\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/hayden_monk\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/hayden_monk/jsons/experiences.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/atharva_arya\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/richard_dow\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/bea_lu\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/sona_chitchyan\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/sona_chitchyan/jsons/education.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/iliomar_rodriguez_ramos\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/jaladh_singhal\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/jack_o_brien\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/jack_o_brien/jsons/experiences.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/cecelia_powers\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/benjamin_mellon\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/benjamin_mellon/jsons/education.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/kevin_cawley\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/sofia_biriouk\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/jing_lu\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/alexander_grunewald\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/alexander_grunewald/jsons/experiences.json\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/harshul_gupta\n",
      "/Users/harshul/projects/kgwebsite/group-data/members/wolfgang_kerzendorf\n"
     ]
    }
   ],
   "source": [
    "# Lists to store data for current and alumni members\n",
    "\n",
    "current_people_page_list = []\n",
    "alumni_people_page_list = []\n",
    "\n",
    "# Looping through member directories to fetch and process member data\n",
    "for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
    "    print(member_dir)\n",
    "    if not (member_info_fname := member_dir / \"info.json\").exists():\n",
    "        continue\n",
    "    else:\n",
    "        member_info = json.load(open(member_info_fname, \"r\"))\n",
    "    education_experience_df, social_links, current_project_title = parse_member_data(\n",
    "        member_dir\n",
    "    )\n",
    "    current_academic_role, is_current_member = extract_member_academic_role(\n",
    "        education_experience_df\n",
    "    )\n",
    "\n",
    "    first_name = member_info[\"first_name\"]\n",
    "    # print(first_name)\n",
    "    last_name = member_info[\"last_name\"]\n",
    "    nickname = member_info.get(\"nick_name\", None)\n",
    "    id = member_info[\"id\"]\n",
    "    image_path = member_info[\"image_path\"]\n",
    "    cover_image_path = member_info[\"cover_image_path\"]\n",
    "\n",
    "    name = f\"{nickname if nickname else first_name} {last_name}\"\n",
    "\n",
    "    member_data = {\n",
    "        \"name\": name,\n",
    "        \"academic_role\": current_academic_role,\n",
    "        \"id\": id,\n",
    "        \"current_project_title\": current_project_title,\n",
    "        \"image_path\": image_path,\n",
    "        \"cover_image_path\": cover_image_path,\n",
    "    }\n",
    "\n",
    "    member_data.update(social_links)\n",
    "\n",
    "    if is_current_member:\n",
    "        current_people_page_list.append(member_data)\n",
    "    else:\n",
    "        alumni_people_page_list.append(member_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_people_page_list\n",
    "# alumni_people_page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering the people page template with data and saving it to a file\n",
    "people_template = environment.get_template(\"people.html.j2\")\n",
    "# Passing lists to jinja2 template\n",
    "people_content = people_template.render(\n",
    "    general=data[\"general\"],\n",
    "    current_members=current_people_page_list,\n",
    "    alumni_members=alumni_people_page_list,\n",
    ")\n",
    "people_file_path = HOSTING_PATH / \"People.html\"\n",
    "\n",
    "with open(people_file_path, mode=\"w\", encoding=\"utf-8\") as people:\n",
    "    people.write(people_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
