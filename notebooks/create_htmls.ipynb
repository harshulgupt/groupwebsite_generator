{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook consist of code for creating the html files for the website each time data is updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classes\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from jinja2.exceptions import UndefinedError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining paths\n",
    "GROUP_DATA_DIR = Path(\"../..//group-data\")\n",
    "MEMBERS_DIR_PATH = GROUP_DATA_DIR / \"members/\"\n",
    "WEBSITE_DATA_PATH = GROUP_DATA_DIR / \"website_data/\"\n",
    "CONTENT_DIR_PATH = WEBSITE_DATA_PATH / \"content\"\n",
    "TEMPLATE_DIR_PATH = GROUP_DATA_DIR.parent / \"groupwebsite_generator\" / \"templates\"\n",
    "HOSTING_PATH = GROUP_DATA_DIR.parent / \"kerzendorf-group.github.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create proper HTML file names by replacing spaces with underscores\n",
    "def page_link(a):\n",
    "    return a.replace(\" \", \"_\") if \" \" in a else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the Environment class that looks for templates. Page_link is set to the global variable so that it can be accessed by all templates\n",
    "environment = Environment(\n",
    "    loader=FileSystemLoader(TEMPLATE_DIR_PATH), extensions=[\"jinja2.ext.loopcontrols\"]\n",
    ")\n",
    "environment.globals[\"page_link\"] = page_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\n",
    "    \"general\",\n",
    "    \"homepage\",\n",
    "    \"research\",\n",
    "    \"support\",\n",
    "    \"contact\",\n",
    "]  # List of JSON files to be processed\n",
    "\n",
    "data = {}\n",
    "# Looping through JSON files and loading their content into the 'data' dictionary\n",
    "for json_file in json_files:\n",
    "    json_file_path = WEBSITE_DATA_PATH / f\"{json_file}.json\"\n",
    "\n",
    "    try:\n",
    "        with open(json_file_path, \"r\") as json_var:\n",
    "            data[json_file] = json.load(json_var)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframes for articles which can be updated further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_content_from_files(columns):\n",
    "    content_data = {col: [] for col in columns}\n",
    "\n",
    "    for json_file in os.listdir(CONTENT_DIR_PATH):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            json_path = os.path.join(CONTENT_DIR_PATH, json_file)\n",
    "            with open(json_path, \"r\") as file:\n",
    "                info = json.load(file)\n",
    "                # Only load those articles where display is True\n",
    "                if info.get(\"display\"):\n",
    "                    for col in columns:\n",
    "                        content_data[col].append(info.get(col))\n",
    "\n",
    "    content_df = pd.DataFrame(content_data)\n",
    "    content_df[\"date\"] = pd.to_datetime(content_df[\"date\"], format=\"%m-%d-%Y\")\n",
    "    return content_df\n",
    "\n",
    "\n",
    "def get_latest_content_df(content_df):\n",
    "    # Sort the entire DataFrame by \"category\" and \"date\" in descending order\n",
    "    sorted_content_df = content_df.sort_values(\n",
    "        by=[\"category\", \"date\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    # Get the first row for each category using groupby and head\n",
    "    latest_content_df = sorted_content_df.groupby(\"category\").head(1).copy()\n",
    "    latest_content_df[\"date\"] = pd.to_datetime(\n",
    "        latest_content_df[\"date\"], format=\"%m-%d-%Y\"\n",
    "    )\n",
    "    latest_content_df = latest_content_df.sort_values(by=\"date\", ascending=False)\n",
    "\n",
    "    return latest_content_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Homepage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing selected columns for Homepage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed columns for homepage\n",
    "columns_initial = [\n",
    "    \"article_id\",\n",
    "    \"category\",\n",
    "    \"date\",\n",
    "    \"tags\",\n",
    "    \"title\",\n",
    "    \"cover_image\",\n",
    "    \"short_description\",\n",
    "]\n",
    "content_df = load_content_from_files(columns_initial)\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering the homepage template with data\n",
    "homepage_template = environment.get_template(\"homepage.html.j2\")\n",
    "homepage_content = homepage_template.render(\n",
    "    general=data[\"general\"],\n",
    "    homepage=data[\"homepage\"],\n",
    "    recent_content=latest_content_df.to_dict(orient=\"records\"),\n",
    ")\n",
    "homepage_html_path = HOSTING_PATH / \"Index.html\"\n",
    "\n",
    "with open(homepage_html_path, mode=\"w\", encoding=\"utf-8\") as homepage:\n",
    "    homepage.write(homepage_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### People Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse member data from JSON files\n",
    "def parse_member_data(member_dir):\n",
    "    member_json_dir = member_dir / \"jsons\"\n",
    "    education_experience_list = []\n",
    "    file_names = [\"experiences.json\", \"education.json\"]\n",
    "    valid_groups = [\"DTI\", \"TARDIS\", \"ICER\", \"kerzendorf\"]\n",
    "    valid_institution = \"Michigan State University\"\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_path = member_json_dir / file_name\n",
    "        if file_path.exists():\n",
    "            # Reading JSON data directly into a DataFrame\n",
    "            df = pd.read_json(file_path)\n",
    "            \n",
    "            # filtering based on group and institution\n",
    "            mask = df.apply(lambda x: x.get('group') in valid_groups or x.get('institution') == valid_institution, axis=1)\n",
    "            filtered_df = df[mask]\n",
    "            \n",
    "            education_experience_list.append(filtered_df)\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist\")\n",
    "\n",
    "    if education_experience_list:\n",
    "        education_experience_df = pd.concat(education_experience_list, ignore_index=True)\n",
    "    else:\n",
    "        education_experience_df = pd.DataFrame()\n",
    "\n",
    "    # if start_date column exists, fill with NaN if it doesn't\n",
    "    if 'start_date' not in education_experience_df:\n",
    "        education_experience_df['start_date'] = pd.NaT\n",
    "    \n",
    "    # Convert start_date to datetime format\n",
    "    education_experience_df['start_date'] = pd.to_datetime(education_experience_df['start_date'], errors='coerce')\n",
    "    \n",
    "    # Sort the DataFrame based on start_date\n",
    "    education_experience_df = education_experience_df.sort_values(by='start_date', ascending=False)\n",
    "\n",
    "    # Load social links directly\n",
    "    social_links = {}\n",
    "    social_links_file_path = member_json_dir / \"social_links.json\"\n",
    "    if social_links_file_path.exists():\n",
    "        with open(social_links_file_path, \"r\") as f:\n",
    "            social_links = json.load(f)\n",
    "\n",
    "    # Load topmost project title\n",
    "    current_project_title = None\n",
    "    projects_file_path = member_json_dir / \"projects.json\"\n",
    "    if projects_file_path.exists():\n",
    "        projects_df = pd.read_json(projects_file_path)\n",
    "        if not projects_df.empty:\n",
    "            current_project_title = projects_df.iloc[0].get(\"project_title\")\n",
    "\n",
    "    return education_experience_df, social_links, current_project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_dir = Path(\"/Users/harshul/projects/kgwebsite/group-data/members/sofia_biriouk\")\n",
    "parse_member_data(member_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract academic roles from education and experience data\n",
    "\n",
    "\n",
    "def extract_member_academic_role(education_experience_df):\n",
    "    # Check if these columns exist in dataframe\n",
    "    for column in [\"end_date\", \"group\", \"institution\"]:\n",
    "        if column not in education_experience_df.columns:\n",
    "            education_experience_df[column] = None\n",
    "\n",
    "    current_academic_role = None\n",
    "\n",
    "    role_map = {\n",
    "        \"Assistant Professor\": \"Professor\",\n",
    "        \"Professor\": \"Professor\",\n",
    "        \"Visualization Consultant\": \"Visualization Consultant\",\n",
    "        \"Research Consultant\": \"Research Consultant\",\n",
    "        \"Research Software Engineer\": \"Research Software Engineer\",\n",
    "        \"Professorial Assistant\": \"Undergraduate\",\n",
    "        \"Visiting Researcher\": \"Postdoctoral Researcher\",\n",
    "        \"Postdoctoral Researcher\": \"Postdoctoral Researcher\",\n",
    "    }\n",
    "\n",
    "    degree_map = {\n",
    "        \"Masters\": \"Graduate Student\",\n",
    "        \"PhD\": \"Postdoctorate\",  #  if end_date is present\n",
    "        \"Bachelors\": \"Graduate Student\",\n",
    "    }\n",
    "\n",
    "    for _, row in education_experience_df.iterrows():\n",
    "        role = row.get(\"role\", None)\n",
    "        degree = row.get(\"degree\", None)\n",
    "\n",
    "        if not current_academic_role:\n",
    "            current_academic_role = role_map.get(role, \"\")\n",
    "\n",
    "            if degree == \"PhD\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Graduate Student\"  # if end_date is NaN\n",
    "            elif degree == \"Bachelors\" and pd.isna(row[\"end_date\"]):\n",
    "                current_academic_role = \"Undergraduate Student\"\n",
    "            elif not current_academic_role and degree in degree_map:\n",
    "                current_academic_role = degree_map[degree]\n",
    "\n",
    "    # Check for end dates outside the loop\n",
    "    has_end_date = all(\n",
    "        not pd.isna(date) for date in education_experience_df[\"end_date\"]\n",
    "    )\n",
    "    is_current_member = not has_end_date\n",
    "\n",
    "    return current_academic_role, is_current_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store data for current and alumni members\n",
    "\n",
    "current_people_page_list = []\n",
    "alumni_people_page_list = []\n",
    "\n",
    "# Looping through member directories to fetch and process member data\n",
    "for member_dir in MEMBERS_DIR_PATH.glob(\"*\"):\n",
    "    print(member_dir)\n",
    "    if not (member_info_fname := member_dir / \"info.json\").exists():\n",
    "        continue\n",
    "    else:\n",
    "        member_info = json.load(open(member_info_fname, \"r\"))\n",
    "    education_experience_df, social_links, current_project_title = parse_member_data(\n",
    "        member_dir\n",
    "    )\n",
    "    current_academic_role, is_current_member = extract_member_academic_role(\n",
    "        education_experience_df\n",
    "    )\n",
    "\n",
    "    first_name = member_info[\"first_name\"]\n",
    "    # print(first_name)\n",
    "    last_name = member_info[\"last_name\"]\n",
    "    nickname = member_info.get(\"nick_name\", None)\n",
    "    id = member_info[\"id\"]\n",
    "    image_path = member_info[\"image_path\"]\n",
    "    cover_image_path = member_info[\"cover_image_path\"]\n",
    "\n",
    "    name = f\"{nickname if nickname else first_name} {last_name}\"\n",
    "\n",
    "    member_data = {\n",
    "        \"name\": name,\n",
    "        \"academic_role\": current_academic_role,\n",
    "        \"id\": id,\n",
    "        \"current_project_title\": current_project_title,\n",
    "        \"image_path\": image_path,\n",
    "        \"cover_image_path\": cover_image_path,\n",
    "    }\n",
    "\n",
    "    member_data.update(social_links)\n",
    "\n",
    "    if is_current_member:\n",
    "        current_people_page_list.append(member_data)\n",
    "    else:\n",
    "        alumni_people_page_list.append(member_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_people_page_list\n",
    "# alumni_people_page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering the people page template with data and saving it to a file\n",
    "people_template = environment.get_template(\"people.html.j2\")\n",
    "# Passing lists to jinja2 template\n",
    "people_content = people_template.render(\n",
    "    general=data[\"general\"],\n",
    "    current_members=current_people_page_list,\n",
    "    alumni_members=alumni_people_page_list,\n",
    ")\n",
    "people_html_path = HOSTING_PATH / \"People.html\"\n",
    "\n",
    "with open(people_html_path, mode=\"w\", encoding=\"utf-8\") as people:\n",
    "    people.write(people_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_template = environment.get_template('contact.html.j2')\n",
    "contact_html_path = HOSTING_PATH / \"Contact.html\"\n",
    "contact_content = contact_template.render(general=data[\"general\"], contact=data[\"contact\"])\n",
    "with open(contact_html_path, mode='w', encoding='utf-8') as contact:\n",
    "    contact.write(contact_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_template = environment.get_template('support.html.j2')\n",
    "support_html_path = HOSTING_PATH / \"Support.html\"\n",
    "support_content = support_template.render(general=data[\"general\"], support=data[\"support\"])\n",
    "with open(support_html_path , mode='w', encoding='utf-8') as support:\n",
    "    support.write(support_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding more columns in dataframe to render fronnt pages and individual article pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_extended = columns_initial + [\"author_id\"]\n",
    "content_df = load_content_from_files(columns_extended)\n",
    "research_content_df = content_df[content_df['category'] != 'News']\n",
    "research_content_df = research_content_df.sort_values(by=['category','date'], ascending=[True, False])\n",
    "latest_content_df = get_latest_content_df(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "research_template = environment.get_template(\"research.html.j2\")\n",
    "main_page_research_content = research_template.render(general=data[\"general\"],\n",
    "                                            content=research_content_df,\n",
    "                                           research=data[\"research\"] ,\n",
    "                                           current_members=current_people_page_list)\n",
    "research_html_path = HOSTING_PATH / \"Research.html\"\n",
    "with open(research_html_path , mode=\"w\", encoding=\"utf-8\") as research:\n",
    "        research.write(main_page_research_content)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_research_template = environment.get_template(\"sub_research_frontpage.html.j2\")\n",
    "\n",
    "\n",
    "for category in content_df.loc[content_df.category != \"News\", \"category\"].unique():\n",
    "        sub_research_content = sub_research_template.render(general=data[\"general\"], \n",
    "                                                            research_general=data[\"research\"], \n",
    "                                                            content = latest_content_df,\n",
    "                                                            category = category\n",
    "                                                            )\n",
    "        folder_path = f\"../kerzendorf-group.github.io/sub_research/{page_link(category.lower())}\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        with open(f\"../kerzendorf-group.github.io/sub_research/{page_link(category.lower())}.html\", mode=\"w\", encoding=\"utf-8\") as sub_research:\n",
    "            sub_research.write(sub_research_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
